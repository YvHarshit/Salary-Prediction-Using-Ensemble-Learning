{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YvHarshit/Salary-Prediction-Using-Ensemble-Learning/blob/main/Salary_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4-ItMLTjuRp",
        "outputId": "c92f2188-854c-4e09-9496-1081c9092d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Individual Base Models\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Ensemble Models\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded_file_name = '/content/sample_data/Latest_Data_Science_Salaries.csv'\n",
        "\n",
        "try:\n",
        "    print(f\"Please upload your '{uploaded_file_name}' file.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Read the uploaded file into a pandas DataFrame\n",
        "    df = pd.read_csv(io.BytesIO(uploaded[uploaded_file_name]))\n",
        "    print(f\"'{uploaded_file_name}' uploaded and loaded successfully!\")\n",
        "    print(\"Dataset head:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nDataset info:\")\n",
        "    df.info()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: '{uploaded_file_name}' not found. Please ensure the file is uploaded correctly.\")\n",
        "    print(\"If you're having trouble, ensure the file name matches exactly.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during file upload or loading: {e}\")\n",
        "    # Create a dummy DataFrame if loading fails to allow code execution for demonstration\n",
        "    print(\"Creating a dummy DataFrame for demonstration purposes.\")\n",
        "    data = {\n",
        "        'work_year': [2023, 2023, 2022, 2023, 2023],\n",
        "        'experience_level': ['SE', 'MI', 'EN', 'SE', 'EX'],\n",
        "        'employment_type': ['FT', 'FT', 'FT', 'FT', 'FT'],\n",
        "        'job_title': ['Data Scientist', 'Machine Learning Engineer', 'Data Analyst', 'Data Scientist', 'Director of Data Science'],\n",
        "        'salary_currency': ['USD', 'USD', 'USD', 'USD', 'USD'],\n",
        "        'salary': [150000, 100000, 80000, 160000, 250000],\n",
        "        'salary_in_usd': [150000, 100000, 80000, 160000, 250000],\n",
        "        'employee_residence': ['US', 'US', 'GB', 'CA', 'US'],\n",
        "        'remote_ratio': [0, 0, 100, 0, 0],\n",
        "        'company_location': ['US', 'US', 'GB', 'CA', 'US'],\n",
        "        'company_size': ['L', 'M', 'S', 'L', 'L']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"Dummy DataFrame created.\")\n",
        "    print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "bEMMapHUkzq5",
        "outputId": "10417c11-ee89-4e64-db95-21caa73d4000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your '/content/sample_data/Latest_Data_Science_Salaries.csv' file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0390adb6-61b6-46ca-b044-94cc831b4a11\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0390adb6-61b6-46ca-b044-94cc831b4a11\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Latest_Data_Science_Salaries.csv to Latest_Data_Science_Salaries.csv\n",
            "An error occurred during file upload or loading: '/content/sample_data/Latest_Data_Science_Salaries.csv'\n",
            "Creating a dummy DataFrame for demonstration purposes.\n",
            "Dummy DataFrame created.\n",
            "   work_year experience_level employment_type                  job_title  \\\n",
            "0       2023               SE              FT             Data Scientist   \n",
            "1       2023               MI              FT  Machine Learning Engineer   \n",
            "2       2022               EN              FT               Data Analyst   \n",
            "3       2023               SE              FT             Data Scientist   \n",
            "4       2023               EX              FT   Director of Data Science   \n",
            "\n",
            "  salary_currency  salary  salary_in_usd employee_residence  remote_ratio  \\\n",
            "0             USD  150000         150000                 US             0   \n",
            "1             USD  100000         100000                 US             0   \n",
            "2             USD   80000          80000                 GB           100   \n",
            "3             USD  160000         160000                 CA             0   \n",
            "4             USD  250000         250000                 US             0   \n",
            "\n",
            "  company_location company_size  \n",
            "0               US            L  \n",
            "1               US            M  \n",
            "2               GB            S  \n",
            "3               CA            L  \n",
            "4               US            L  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Data Preprocessing ---\")\n",
        "\n",
        "# 3.1 Handle Missing Values\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values before handling:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtH63Bnrm6vR",
        "outputId": "d8217cd3-ddaa-4942-9636-858618236e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Preprocessing ---\n",
            "\n",
            "Missing values before handling:\n",
            "work_year             0\n",
            "experience_level      0\n",
            "employment_type       0\n",
            "job_title             0\n",
            "salary_currency       0\n",
            "salary                0\n",
            "salary_in_usd         0\n",
            "employee_residence    0\n",
            "remote_ratio          0\n",
            "company_location      0\n",
            "company_size          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For simplicity, we'll drop rows with any missing values.\n",
        "# In a real project, you might use imputation strategies (mean, median, mode)\n",
        "# based on the nature of the missing data.\n",
        "df.dropna(inplace=True)\n",
        "print(\"\\nMissing values after dropping rows:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"DataFrame shape after dropping NaNs: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ignZ1lPTm9LB",
        "outputId": "50875352-a59d-4a2c-c903-cd7a5e16f337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values after dropping rows:\n",
            "work_year             0\n",
            "experience_level      0\n",
            "employment_type       0\n",
            "job_title             0\n",
            "salary_currency       0\n",
            "salary                0\n",
            "salary_in_usd         0\n",
            "employee_residence    0\n",
            "remote_ratio          0\n",
            "company_location      0\n",
            "company_size          0\n",
            "dtype: int64\n",
            "DataFrame shape after dropping NaNs: (5, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The target variable is 'salary_in_usd'.\n",
        "target = 'salary_in_usd'\n",
        "features = [col for col in df.columns if col not in ['salary', 'salary_currency', target]]\n",
        "\n",
        "# Separate features into numerical and categorical\n",
        "numerical_features = df[features].select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = df[features].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(f\"\\nNumerical features: {numerical_features}\")\n",
        "print(f\"Categorical features: {categorical_features}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td4Ly_m4nQx-",
        "outputId": "c251a79a-4743-4ba1-9cb3-ccb9b99b2663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numerical features: ['work_year', 'remote_ratio']\n",
            "Categorical features: ['experience_level', 'employment_type', 'job_title', 'employee_residence', 'company_location', 'company_size']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical pipeline: just scaling\n",
        "numerical_transformer = StandardScaler()\n",
        "\n",
        "# Categorical pipeline: one-hot encoding\n",
        "# handle_unknown='ignore' will set unknown categories to all zeros, preventing errors\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"\\nPreprocessing pipeline created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jubQ_iDknZyN",
        "outputId": "74c20588-c491-41a3-bd88-75744c7b6678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessing pipeline created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical pipeline: just scaling\n",
        "numerical_transformer = StandardScaler()\n",
        "\n",
        "# Categorical pipeline: one-hot encoding\n",
        "# handle_unknown='ignore' will set unknown categories to all zeros, preventing errors\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"\\nPreprocessing pipeline created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNTCkzENniSB",
        "outputId": "87e4a2ce-1663-4c76-87e8-65ec835b59f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessing pipeline created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Stacking Regressor\n",
        "# The meta-model will learn how to combine the predictions of the base estimators.\n",
        "# We'll use a subset of the base models for stacking to demonstrate.\n",
        "stacked_regressor = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('rf', RandomForestRegressor(n_estimators=50, random_state=42)), # Using fewer estimators for faster training in stacking\n",
        "        ('xgb', xgb.XGBRegressor(n_estimators=50, random_state=42, use_label_encoder=False, eval_metric='rmse')),\n",
        "        ('svr', SVR())\n",
        "    ],\n",
        "    final_estimator=Ridge(random_state=42), # Ridge Regression as the meta-model\n",
        "    cv=3, # Number of cross-validation folds for stacking - Reduced for small dataset\n",
        "    n_jobs=-1 # Use all available cores\n",
        ")\n",
        "\n",
        "# Define individual models\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "xgb_model = xgb.XGBRegressor(random_state=42, use_label_encoder=False, eval_metric='rmse')\n",
        "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
        "\n",
        "\n",
        "# Create a dictionary of all models to train and evaluate\n",
        "models = {\n",
        "    \"Linear Regression\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
        "    \"Decision Tree\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', DecisionTreeRegressor(random_state=42))]),\n",
        "    \"Support Vector Regressor\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', SVR())]),\n",
        "    \"K-Nearest Neighbors\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', KNeighborsRegressor(n_neighbors=3))]), # Reduced n_neighbors\n",
        "    \"Random Forest\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', rf_model)]),\n",
        "    \"Gradient Boosting\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', gb_model)]),\n",
        "    \"XGBoost\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', xgb_model)]),\n",
        "    \"LightGBM\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb_model)]),\n",
        "    \"Stacked Regressor\": Pipeline(steps=[('preprocessor', preprocessor), ('regressor', stacked_regressor)])\n",
        "}\n",
        "\n",
        "print(\"\\nModels defined and pipelines created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz3oe3y4nqCE",
        "outputId": "851966d6-a04e-4e1d-acc9-2ce2794832da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Models defined and pipelines created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Model Training and Evaluation ---\")\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"\\nData split into training ({X_train.shape[0]} samples) and testing ({X_test.shape[0]} samples).\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "# K-Fold Cross-Validation setup\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining and evaluating {name}...\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Perform K-Fold Cross-Validation\n",
        "    # Note: cross_val_score will internally create new pipelines for each fold,\n",
        "    # so the preprocessor will be fit correctly on each fold's training data.\n",
        "    cv_mae_scores = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "    cv_rmse_scores = np.sqrt(-cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1))\n",
        "    cv_r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2', n_jobs=-1)\n",
        "\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2,\n",
        "        'CV_MAE_Mean': cv_mae_scores.mean(),\n",
        "        'CV_MAE_Std': cv_mae_scores.std(),\n",
        "        'CV_RMSE_Mean': cv_rmse_scores.mean(),\n",
        "        'CV_RMSE_Std': cv_rmse_scores.std(),\n",
        "        'CV_R2_Mean': cv_r2_scores.mean(),\n",
        "        'CV_R2_Std': cv_r2_scores.std()\n",
        "    }\n",
        "\n",
        "    print(f\"{name} - Test Set Metrics:\")\n",
        "    print(f\"  MAE: {mae:.2f}\")\n",
        "    print(f\"  RMSE: {rmse:.2f}\")\n",
        "    print(f\"  R-squared: {r2:.4f}\")\n",
        "    print(f\"  Cross-Validation MAE: {cv_mae_scores.mean():.2f} (+/- {cv_mae_scores.std():.2f})\")\n",
        "    print(f\"  Cross-Validation RMSE: {cv_rmse_scores.mean():.2f} (+/- {cv_rmse_scores.std():.2f})\")\n",
        "    print(f\"  Cross-Validation R-squared: {cv_r2_scores.mean():.4f} (+/- {cv_r2_scores.std():.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwLRIvvkn1n4",
        "outputId": "be491e72-192f-4d9b-aa65-662d6819824e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Training and Evaluation ---\n",
            "\n",
            "Data split into training (4 samples) and testing (1 samples).\n",
            "\n",
            "Training and evaluating Linear Regression...\n",
            "Linear Regression - Test Set Metrics:\n",
            "  MAE: 86607.14\n",
            "  RMSE: 86607.14\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 68583.77 (+/- 37218.07)\n",
            "  Cross-Validation RMSE: 68583.77 (+/- 37218.07)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating Decision Tree...\n",
            "Decision Tree - Test Set Metrics:\n",
            "  MAE: 50000.00\n",
            "  RMSE: 50000.00\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 68000.00 (+/- 46647.62)\n",
            "  Cross-Validation RMSE: 68000.00 (+/- 46647.62)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating Support Vector Regressor...\n",
            "Support Vector Regressor - Test Set Metrics:\n",
            "  MAE: 54999.90\n",
            "  RMSE: 54999.90\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 61999.78 (+/- 36551.39)\n",
            "  Cross-Validation RMSE: 61999.78 (+/- 36551.39)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating K-Nearest Neighbors...\n",
            "K-Nearest Neighbors - Test Set Metrics:\n",
            "  MAE: 86666.67\n",
            "  RMSE: 86666.67\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 56666.67 (+/- 39888.73)\n",
            "  Cross-Validation RMSE: 56666.67 (+/- 39888.73)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating Random Forest...\n",
            "Random Forest - Test Set Metrics:\n",
            "  MAE: 66400.00\n",
            "  RMSE: 66400.00\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 56860.00 (+/- 43813.54)\n",
            "  Cross-Validation RMSE: 56860.00 (+/- 43813.54)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating Gradient Boosting...\n",
            "Gradient Boosting - Test Set Metrics:\n",
            "  MAE: 26443.68\n",
            "  RMSE: 26443.68\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 47357.33 (+/- 48634.04)\n",
            "  Cross-Validation RMSE: 47357.33 (+/- 48634.04)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating XGBoost...\n",
            "XGBoost - Test Set Metrics:\n",
            "  MAE: 50000.02\n",
            "  RMSE: 50000.02\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 58000.01 (+/- 51536.40)\n",
            "  Cross-Validation RMSE: 58000.01 (+/- 51536.39)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating LightGBM...\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 4, number of used features: 0\n",
            "[LightGBM] [Info] Start training from score 160000.000000\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "LightGBM - Test Set Metrics:\n",
            "  MAE: 60000.00\n",
            "  RMSE: 60000.00\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 58000.00 (+/- 45809.39)\n",
            "  Cross-Validation RMSE: 58000.00 (+/- 45809.39)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n",
            "\n",
            "Training and evaluating Stacked Regressor...\n",
            "Stacked Regressor - Test Set Metrics:\n",
            "  MAE: 966307.57\n",
            "  RMSE: 966307.57\n",
            "  R-squared: nan\n",
            "  Cross-Validation MAE: 80342787.31 (+/- 148105635.89)\n",
            "  Cross-Validation RMSE: 80342787.31 (+/- 148105635.89)\n",
            "  Cross-Validation R-squared: nan (+/- nan)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display all results in a table\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\n--- All Model Evaluation Results ---\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Identify the best performing model based on R-squared (higher is better)\n",
        "best_model_name = results_df['R2'].idxmax()\n",
        "print(f\"\\nBest performing model on test set (based on R-squared): {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbxOWwqQp4oH",
        "outputId": "59a09128-3882-44da-e160-10100dd2fac6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- All Model Evaluation Results ---\n",
            "                                  MAE         RMSE  R2   CV_MAE_Mean  \\\n",
            "Linear Regression          86607.1429   86607.1429 NaN  6.858377e+04   \n",
            "Decision Tree              50000.0000   50000.0000 NaN  6.800000e+04   \n",
            "Support Vector Regressor   54999.9028   54999.9028 NaN  6.199978e+04   \n",
            "K-Nearest Neighbors        86666.6667   86666.6667 NaN  5.666667e+04   \n",
            "Random Forest              66400.0000   66400.0000 NaN  5.686000e+04   \n",
            "Gradient Boosting          26443.6788   26443.6788 NaN  4.735733e+04   \n",
            "XGBoost                    50000.0156   50000.0154 NaN  5.800001e+04   \n",
            "LightGBM                   60000.0000   60000.0000 NaN  5.800000e+04   \n",
            "Stacked Regressor         966307.5660  966307.5660 NaN  8.034279e+07   \n",
            "\n",
            "                            CV_MAE_Std  CV_RMSE_Mean   CV_RMSE_Std  \\\n",
            "Linear Regression         3.721807e+04  6.858377e+04  3.721807e+04   \n",
            "Decision Tree             4.664762e+04  6.800000e+04  4.664762e+04   \n",
            "Support Vector Regressor  3.655139e+04  6.199978e+04  3.655139e+04   \n",
            "K-Nearest Neighbors       3.988873e+04  5.666667e+04  3.988873e+04   \n",
            "Random Forest             4.381354e+04  5.686000e+04  4.381354e+04   \n",
            "Gradient Boosting         4.863404e+04  4.735733e+04  4.863404e+04   \n",
            "XGBoost                   5.153640e+04  5.800001e+04  5.153639e+04   \n",
            "LightGBM                  4.580939e+04  5.800000e+04  4.580939e+04   \n",
            "Stacked Regressor         1.481056e+08  8.034279e+07  1.481056e+08   \n",
            "\n",
            "                          CV_R2_Mean  CV_R2_Std  \n",
            "Linear Regression                NaN        NaN  \n",
            "Decision Tree                    NaN        NaN  \n",
            "Support Vector Regressor         NaN        NaN  \n",
            "K-Nearest Neighbors              NaN        NaN  \n",
            "Random Forest                    NaN        NaN  \n",
            "Gradient Boosting                NaN        NaN  \n",
            "XGBoost                          NaN        NaN  \n",
            "LightGBM                         NaN        NaN  \n",
            "Stacked Regressor                NaN        NaN  \n",
            "\n",
            "Best performing model on test set (based on R-squared): nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Predicting Salary with Sample Data ---\")\n",
        "\n",
        "# Get the best trained model\n",
        "# Check if best_model_name is NaN due to small dataset issues and assign a default if necessary\n",
        "if pd.isna(best_model_name):\n",
        "    print(\"Warning: R-squared values were all NaN. Assigning 'Linear Regression' as the best model for demonstration.\")\n",
        "    best_model_name = 'Linear Regression'\n",
        "\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "# Define a function to predict salary for new sample data\n",
        "def predict_new_salary(model, sample_data):\n",
        "\n",
        "    if isinstance(sample_data, dict):\n",
        "        sample_df = pd.DataFrame([sample_data])\n",
        "    elif isinstance(sample_data, list):\n",
        "        sample_df = pd.DataFrame(sample_data)\n",
        "    else:\n",
        "        raise ValueError(\"sample_data must be a dictionary or a list of dictionaries.\")\n",
        "\n",
        "    # Ensure the sample data has the same columns as the training data features\n",
        "    # Fill missing columns with NaN, which the preprocessor might handle or you can impute\n",
        "    for col in features:\n",
        "        if col not in sample_df.columns:\n",
        "            sample_df[col] = np.nan # Or a default value if appropriate\n",
        "\n",
        "    # Reorder columns to match the training data's feature order\n",
        "    sample_df = sample_df[features]\n",
        "\n",
        "    # Predict\n",
        "    predicted_salary = model.predict(sample_df)\n",
        "    return predicted_salary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs3KT5e4qq1Y",
        "outputId": "130fa540-b961-4de1-b82f-992bb5005ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Predicting Salary with Sample Data ---\n",
            "Warning: R-squared values were all NaN. Assigning 'Linear Regression' as the best model for demonstration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is Example of how to use the predict_new_salary function..\n",
        "sample_new_data = {\n",
        "    'work_year': 2024,\n",
        "    'experience_level': 'SE',\n",
        "    'employment_type': 'FT',\n",
        "    'job_title': 'Data Scientist',\n",
        "    'employee_residence': 'US',\n",
        "    'remote_ratio': 0,\n",
        "    'company_location': 'US',\n",
        "    'company_size': 'M'\n",
        "}\n",
        "\n",
        "predicted_salary = predict_new_salary(best_model, sample_new_data)\n",
        "print(f\"\\nPredicted salary for the sample data: ${predicted_salary[0]:,.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1jyLr5IOgnY",
        "outputId": "2e7d0ec0-7949-493c-a6db-946964190366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted salary for the sample data: $179,017.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_new_3 = {\n",
        "    'work_year': 2025,\n",
        "    'experience_level': 'EX', # Executive\n",
        "    'employment_type': 'FT',\n",
        "    'job_title': 'Director of Data Science',\n",
        "    'salary_currency': 'GBP',\n",
        "    'employee_residence': 'GB', # United Kingdom\n",
        "    'remote_ratio': 0, # Fully in-person\n",
        "    'company_location': 'GB',\n",
        "    'company_size': 'L' # Large company\n",
        "}\n",
        "predicted_salary = predict_new_salary(best_model, sample_new_3)\n",
        "print(f\"\\nPredicted salary for the sample data: ${predicted_salary[0]:,.2f}\")"
      ],
      "metadata": {
        "id": "g7sqwmN42DaT",
        "outputId": "cccb2b54-1e76-4378-dc45-6737edc02faf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted salary for the sample data: $306,339.29\n"
          ]
        }
      ]
    }
  ]
}